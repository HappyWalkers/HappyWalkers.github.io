{"meta":{"title":"Yunpeng's Blog","subtitle":"","description":"","author":"Yunpeng Wang","url":"https://happywalkers.github.io","root":"/"},"pages":[],"posts":[{"title":"Raft","slug":"Raft","date":"2024-02-25T05:15:24.000Z","updated":"2024-02-25T05:31:55.013Z","comments":true,"path":"2024/02/25/Raft/","link":"","permalink":"https://happywalkers.github.io/2024/02/25/Raft/","excerpt":"","text":"RaftRaft is a consensus algorithm designed to be more understandable and practical than Paxos. Raft separates key consensus elements like leader election, log replication, and safety into distinct components to simplify comprehension and implementation. It introduces a novel approach for cluster membership changes and emphasizes understandability without compromising efficiency. Raft aims to provide a foundation for building reliable, large-scale software systems through a structured framework that simplifies the consensus process. data racingRule 1: Whenever you have data that more than one goroutine uses, andat least one goroutine might modify the data, the goroutines shoulduse locks to prevent simultaneous use of the data. The Go racedetector is pretty good at detecting violations of this rule (thoughit won’t help with any of the rules below). Granularity of locksRule 2: Whenever code makes a sequence of modifications to shareddata, and other goroutines might malfunction if they looked at thedata midway through the sequence, you should use a lock around thewhole sequence. An example: rf.mu.Lock() rf.currentTerm +&#x3D; 1 rf.state &#x3D; Candidate rf.mu.Unlock() It would be a mistake for another goroutine to see either of theseupdates alone (i.e. the old state with the new term, or the new termwith the old state). So we need to hold the lock continuously over thewhole sequence of updates. All other code that uses rf.currentTerm orrf.state must also hold the lock, in order to ensure exclusive accessfor all uses. The code between Lock() and Unlock() is often called a “criticalsection.” The locking rules a programmer chooses (e.g. “a goroutinemust hold rf.mu when using rf.currentTerm or rf.state”) are oftencalled a “locking protocol”. Rule 3: Whenever code does a sequence of reads of shared data (orreads and writes), and would malfunction if another goroutine modifiedthe data midway through the sequence, you should use a lock around thewhole sequence. An example that could occur in a Raft RPC handler: rf.mu.Lock() if args.Term &gt; rf.currentTerm { rf.currentTerm &#x3D; args.Term } rf.mu.Unlock() This code needs to hold the lock continuously for the whole sequence.Raft requires that currentTerm only increases, and never decreases.Another RPC handler could be executing in a separate goroutine; if itwere allowed to modify rf.currentTerm between the if statement and theupdate to rf.currentTerm, this code might end up decreasingrf.currentTerm. Hence the lock must be held continuously over thewhole sequence. In addition, every other use of currentTerm must holdthe lock, to ensure that no other goroutine modifies currentTermduring our critical section. Real Raft code would need to use longer critical sections than theseexamples; for example, a Raft RPC handler should probably hold thelock for the entire handler. ConcurrencyRule 4: It’s usually a bad idea to hold a lock while doing anythingthat might wait: reading a Go channel, sending on a channel, waitingfor a timer, calling time.Sleep(), or sending an RPC (and waiting for thereply). One reason is that you probably want other goroutines to makeprogress during the wait. Another reason is deadlock avoidance. Imaginetwo peers sending each other RPCs while holding locks; both RPChandlers need the receiving peer’s lock; neither RPC handler can evercomplete because it needs the lock held by the waiting RPC call. Code that waits should first release locks. If that’s not convenient,sometimes it’s useful to create a separate goroutine to do the wait. Rule 5: Be careful about assumptions across a drop and re-acquire of alock. One place this can arise is when avoiding waiting with locksheld. For example, this code to send vote RPCs is incorrect: rf.mu.Lock() rf.currentTerm +&#x3D; 1 rf.state &#x3D; Candidate for { go func() { rf.mu.Lock() args.Term &#x3D; rf.currentTerm rf.mu.Unlock() Call(“Raft.RequestVote”, &amp;args, …) &#x2F;&#x2F; handle the reply… } () } rf.mu.Unlock() The code sends each RPC in a separate goroutine. It’s incorrectbecause args.Term may not be the same as the rf.currentTerm at whichthe surrounding code decided to become a Candidate. Lots of time maypass between when the surrounding code creates the goroutine and whenthe goroutine reads rf.currentTerm; for example, multiple terms maycome and go, and the peer may no longer be a candidate. One way to fixthis is for the created goroutine to use a copy of rf.currentTerm madewhile the outer code holds the lock. Similarly, reply-handling codeafter the Call() must re-check all relevant assumptions afterre-acquiring the lock; for example, it should check thatrf.currentTerm hasn’t changed since the decision to become acandidate. It can be difficult to interpret and apply these rules. Perhaps mostpuzzling is the notion in Rules 2 and 3 of code sequences thatshouldn’t be interleaved with other goroutines’ reads or writes. Howcan one recognize such sequences? How should one decide where asequence ought to start and end? One approach is to start with code that has no locks, and thinkcarefully about where one needs to add locks to attain correctness.This approach can be difficult since it requires reasoning about thecorrectness of concurrent code. A more pragmatic approach starts with the observation that if therewere no concurrency (no simultaneously executing goroutines), youwould not need locks at all. But you have concurrency forced on youwhen the RPC system creates goroutines to execute RPC handlers, andbecause you need to send RPCs in separate goroutines to avoid waiting.You can effectively eliminate this concurrency by identifying allplaces where goroutines start (RPC handlers, background goroutines youcreate in Make(), &amp;c), acquiring the lock at the very start of eachgoroutine, and only releasing the lock when that goroutine hascompletely finished and returns. This locking protocol ensures thatnothing significant ever executes in parallel; the locks ensure thateach goroutine executes to completion before any other goroutine isallowed to start. With no parallel execution, it’s hard to violateRules 1, 2, 3, or 5. If each goroutine’s code is correct in isolation(when executed alone, with no concurrent goroutines), it’s likely tostill be correct when you use locks to suppress concurrency. So youcan avoid explicit reasoning about correctness, or explicitlyidentifying critical sections. However, Rule 4 is likely to be a problem. So the next step is to findplaces where the code waits, and to add lock releases and re-acquires(and&#x2F;or goroutine creation) as needed, being careful to re-establishassumptions after each re-acquire. You may find this process easier toget right than directly identifying sequences that must be locked forcorrectness. (As an aside, what this approach sacrifices is any opportunity forbetter performance via parallel execution on multiple cores: your codeis likely to hold locks when it doesn’t need to, and may thusunnecessarily prohibit parallel execution of goroutines. On the otherhand, there is not much opportunity for CPU parallelism within asingle Raft peer.) Correctness in stress testsThe program passes 10000 2A tests with 300 concurrent tests but failes with 400.The main reason maybe the test itself. The test use a object in memory to emulate a network. So when the system is extremely resource-constrained, the fake network in the process may not be scheduled on CPU so the message delivery is delayed long enough to cause the test failed. But this doesn’t mean Raft is incorrect. In 2AInitialTest, the problem is that servers disagree on the term. But the dissent will eventually be eliminated because the leader with larger term will establish authority if the failure is tolertable.Another potential problem is if the machine is under heavy load, for example, CPU and memory is severely constrained, the electionTimer may not work correctly. The reason is the timer&#x2F;ticker implemented in go is checked iteratively by a goroutine. So when the goroutine cannot be scheduled on CPU, the timer&#x2F;ticker cannot fire correctly and precisely. Thus, in Raft case, the election timer cannot fire precisely. DeadlockThe story is that I acquire a read lock and only release it in certain conditions. I guess the best practice is never acquiring and releasing a lock at different levels. And maybe never seperate the two operations too far away from each other, for example,by writing more than 20 lines between them. Problems in testsThe program also pass 19999 tests in 20000 tests. The failed one is caused by the wrong implementations of tests.Specifically, when there are two leaders in the network, the client have to wait until only one leader is left, while the test just picks the one with a smaller id.It can be proved that when there is only one leader, it’s safe to submit commands. The two leader scene can only caused by network partitions that isolate an old leader from the majority and force the new leader with a larger term to be picked. Then when the network partition disappeared, the old leader cannot beat the new leader because the old leader has a smaller term. It basically passes all the tests in 2ABCD except sometimes fail in 2B tests because of the test itself or because of other not-so-well implementations.Read the TODOs in the code and consider improving the code based on those TODOs.But the TODOs may not be perfectly correct. It’s hard to see if it’s correct without testing. ReferenceRaft paper: https://raft.github.io/raft.pdfMy implementation: https://github.com/HappyWalkers/Raft","categories":[],"tags":[{"name":"Distributed System","slug":"Distributed-System","permalink":"https://happywalkers.github.io/tags/Distributed-System/"}]},{"title":"Chord","slug":"chord","date":"2024-02-25T03:27:16.029Z","updated":"2024-02-25T03:27:16.029Z","comments":true,"path":"2024/02/25/chord/","link":"","permalink":"https://happywalkers.github.io/2024/02/25/chord/","excerpt":"","text":"SummaryChord functions as a protocol and algorithm for a peer-to-peer distributed hash table. It enables efficient key&#x2F;value storage and retrieval by assigning keys to nodes in a network, ensuring data can be found quickly even as nodes join or leave. Chord is particularly useful in decentralized applications such as file-sharing systems, distributed file systems, and in implementing resilient, scalable distributed systems. Its time complexity for lookup operations is O(logn), where n is the number of nodes in the system. Chord distinguishes itself from other systems with its simplicity, provable correctness, and scalability, mainly due to its consistent hashing mechanism that minimizes key reassignment when nodes change. ImplementationForm a ringThe simple ring-forming algorithm in Chord, as depicted, is designed to facilitate the location of the successor node responsible for a given key. The process is straightforward: a node�� n queries the next node in the ring, referred to as its “successor,” to find the appropriate successor of an identifier�� id. �� id is within the range of no� n and its successor, node� n responds with its successor. Otherwise, the query is forwarded along the ring to the successor of� n, and the process repeats until the correct node is found. This basic algorithm underpins Chord’s distributed data location strategy, ensuring efficient data retrieval in a scalable peer-to-peer network. Scalable key lookup The image depicts a Chord protocol’s finger table for node 8 and illustrates how a query traverses the Chord ring. Each entry in the finger table points to the first node that succeeds the start of the finger’s interval on the identifier circle. For instance, finger k corresponds to the node that succeeds the identifier (n + 2^(k-1)) modulo 2^m. The successor is the node’s immediate successor on the identifier circle, while the predecessor is the immediate predecessor on this circle. When a node receives a query for an identifier, it uses the finger table to find the closest preceding node to the identifier and forwards the query to it. This process continues until the node responsible for the identifier is reached. This efficient lookup method greatly reduces the number of hops needed to find a successor, especially in large networks. Create, join, stablization, fix finger, and check predecessorCreating the Chord Ring (n.create()):A node initializes the Chord ring by setting its predecessor as nil and its successor as itself.It effectively creates a new network where it is the only node in the ring. Joining the Chord Ring (n.join(n’)):When a node wants to join an existing network, it invokes the join function.It sets its predecessor as nil and finds its successor by using find_successor on a known node in the Chord network.This process is called join stabilization, where the node integrates itself into the network and updates the relevant successor and predecessor pointers of neighboring nodes. Stabilization (n.stabilize()):Each node runs stabilize periodically to learn about new nodes and to ensure the network correctly reflects the set of nodes.During stabilization, each node checks with its successor for the successor’s predecessor p and decides if p should be its successor. It also informs the successor about its presence so the successor can update its predecessor if necessary. Fixing Fingers (n.fix_fingers()):Each node periodically updates its finger table, which is a set of shortcuts to facilitate faster lookups.The fix_fingers function incrementally updates these entries to point to the correct nodes, improving the efficiency of lookups. Checking Predecessor (n.check_predecessor()):This function is called periodically to check if the predecessor has failed.If the predecessor has failed, it sets the predecessor to nil. This is a cleanup process to maintain the correctness of the ring in case of node failures. CallbackI implemented Chord using ns3, which only provides an asynchronous API for sending and receiving messages across the network. This asynchronous approach, while not standard, significantly accelerates the simulation. However, it complicates handling any Remote Procedure Call (RPC) that expects a return value. For instance, the find_successor function, which returns the successor of a given key ‘id’, poses a challenge: 1successor = n.find_successor(id); This function triggers a send_packet operation to send a message to another node. However, since this function does not block, the return value isn’t immediately available. Instead, the return value is received through another message from the node that finds the successor to key ‘id’. Due to this asynchronous call and the delay in receiving return values, any function issuing a send_packet operation must be split into two distinct functions: one for initiating the send operation and another for handling the return value. This division disrupts the flow of logic and complicates code readability. To address this, I designed a callback mechanism to streamline the logic. I utilized a hashmap to associate each transaction_id with a function object capable of processing the return value of the sent packet. When the response to the sent packet is received, the corresponding function in the hashmap is invoked directly, eliminating the need to manually manage the return value handling in the code. An example of this process is illustrated below, where the callback is registered and stored in a hashmap. 12345678910111213141516171819202122232425262728293031323334// Each node also runs check predecessor periodically,// to clear the node’s predecessor pointer if n.predecessor has failed;// this allows it to accept a new predecessor in notify.void PennChord::checkPredecessor()&#123; // std::cout &lt;&lt; ReverseLookup(GetLocalAddress()) &lt;&lt; &quot; checkes predecessor &quot; &lt;&lt; &quot;\\n&quot;; // check the last time the node receive the pingRsp from its predecessor // if the currentTime - lastTime &gt; threshold, the node think its predecessor failed and set its predecessor to itself if(Simulator::Now() - lastTimePredecessorRsp &gt; this-&gt;DEAD_TIMEOUT) &#123; SetPredecessor(GetLocalAddress(), ReverseLookup(GetLocalAddress()), PennKeyHelper::CreateShaKey(GetLocalAddress())); &#125; // register a callback to update the lastTimePredecessorRsp uint32_t transactionId = GetNextTransactionId(); transactionIdToCallbackMapSync.put( transactionId, [this](PennChordMessage message, Ipv4Address sourceAddress, uint16_t sourcePort) -&gt; void &#123; this-&gt;lastTimePredecessorRsp = Simulator::Now(); &#125; ); // ping predecessor std::string pingMessage = &quot;I&#x27;m your successor. Reply if you are alive.&quot;; Ptr&lt;PingRequest&gt; pingRequest = Create&lt;PingRequest&gt;(transactionId, Simulator::Now(), m_predecessor-&gt;nodeIp, pingMessage); m_pingTracker.insert(std::make_pair(transactionId, pingRequest)); Ptr&lt;Packet&gt; packet = Create&lt;Packet&gt;(); PennChordMessage message = PennChordMessage(PennChordMessage::PING_REQ, transactionId); message.SetPingReq(pingMessage); packet-&gt;AddHeader(message); m_socket-&gt;SendTo(packet, 0, InetSocketAddress(m_predecessor-&gt;nodeIp, m_appPort)); checkPredecessorTimer.Schedule(checkPredecessorTimeout);&#125; The callback is called when the returned value is sent back with a message. 1234567891011void PennChord::ProcessPingRsp(PennChordMessage message, Ipv4Address sourceAddress, uint16_t sourcePort)&#123; // do something try&#123; transactionIdToCallbackMapSync.get(message.GetTransactionId())(message, sourceAddress, sourcePort); transactionIdToCallbackMapSync.erase(message.GetTransactionId()); &#125;catch(std::out_of_range &amp; e) &#123; std::cout &lt;&lt; e.what() &lt;&lt; std::endl; &#125; // do something else&#125; ReferenceChord paper: https://pdos.csail.mit.edu/papers/ton:chord/paper-ton.pdf","categories":[],"tags":[{"name":"Distributed Systems","slug":"Distributed-Systems","permalink":"https://happywalkers.github.io/tags/Distributed-Systems/"}]},{"title":"Google-style Search Engine - A distributed system","slug":"cis555","date":"2023-09-04T22:41:46.000Z","updated":"2024-02-25T03:35:44.477Z","comments":true,"path":"2023/09/04/cis555/","link":"","permalink":"https://happywalkers.github.io/2023/09/04/cis555/","excerpt":"","text":"ImplementationHTTP Protocol and Web ServerHTTP 1.1https://www.ietf.org/rfc/rfc2616.txt Distributed Key Value StoreRDD (Resilient Dataset)the table that represents an RDD R :&#x3D; {v 1 , v 2 , . . . , v n } should have n rows; row #i should have an arbitrary but unique key and a column called value, which should contain v i . The keys should be at least somewhat random, so the table will be spread roughly evenly across the workers. Pair RDDThe table that represents a PairRDD P :&#x3D; {(k 1 , v 1 ), (k 2 , v 2 ), . . . , (k n , v n )} should have as many rows as there are unique keys in the RDD; the row for an RDD key k should have k as its KVS key, and a column with a unique name for each value v j , where (k, v j ) ∈ P ; the value in that column should be v jA row in kvs can be parsed as many Pair RDDs. Flame: Distributed Data Analysis Framework Page Rank Load the data (PageRank): make (u,”1.0,1.0,L”) pairs, where L is a comma-separated list of normalized links you found on the page with URL u. We’ll call this the “state table” below. Compute the transfer table: For each pair (u,”r c ,r p ,L”), where L contains n URLs, compute n pairs (l i ,v), where v &#x3D; 0.85 · r c &#x2F;n. In other words, each of the pages that page u has a link to gets a fraction 1&#x2F;n of u’s current rank r c , with the decay factor d &#x3D; 0.85 already applied. Aggregate the transfers: adding up all the v i from the many P (u,v i ) pairs for each page u Update the state table: At this point, we have two PairRDDs: the old state table and an aggregated transfer table, both with the page URL as the key. We need to move the “new” rank from the latter to the former. To do this, first invoke join, which will combine the elements from both tables by URL, and concatenate the values, separated by a comma. This is not yet what we want – there are more fields in the join result than in the original state table – so you’ll have to follow up with another flatMapToPair that throws out the old “previous rank” entry, moves the old “current rank” entry to the new “previous rank” entry, and moves the newly computed aggregate to the “current rank” entry. This is also a good opportunity to add the 0.15 from the rank source. Iterate, and check for convergence: Put the code so far (after the initial load) into an infinite loop; at the end of the loop, replace the old state table with the new one, and then compute the maximum change in ranks across all the pages. This can be done with a flatMap, where you compute the absolute difference between the old and current ranks for each page, followed by a fold that computes the maximum of these. If the maximum is below the convergence threshold, exit the loop. TF-IDF Load the crawler data. Extract and clean words from page body. For each distinct set of words from body, count the number of occurences of a word from the particular page body. Add distinct words into a persistent table, ‘index’, with unique words as key. For value, add a string concatenated with the hashed url and number of word occurences, e.g. ahzxghtoiu:1 (meaning there is 1 occurence of word in hashed url of ahzxghtoiu). Once all words are processed for all crawler data, calculate the IDF value by retrieving the occurrences of words that occur in different pages. The formula used to calculate TF-IDF in our case is log normalization-IDF, which is (1 + log f_t,d) * log (N&#x2F;n_t), where f_t,d is the term frequency in a particular page, N is the total number of unique words in the index, n is the number of documents that contain the particular word&#x2F;term. ** Note: IDF values are only calculated for query words, i.e. the value will be generated when the query comes in. Report","categories":[],"tags":[{"name":"Distributed Systems","slug":"Distributed-Systems","permalink":"https://happywalkers.github.io/tags/Distributed-Systems/"}]},{"title":"Drone - path planning, trajectory planning, and PID controller","slug":"meam620","date":"2023-09-04T22:41:42.000Z","updated":"2024-02-25T03:36:02.509Z","comments":true,"path":"2023/09/04/meam620/","link":"","permalink":"https://happywalkers.github.io/2023/09/04/meam620/","excerpt":"","text":"Report","categories":[],"tags":[{"name":"Robotics","slug":"Robotics","permalink":"https://happywalkers.github.io/tags/Robotics/"}]},{"title":"Robot arm control","slug":"meam520","date":"2023-09-04T22:25:58.000Z","updated":"2024-02-25T03:31:41.121Z","comments":true,"path":"2023/09/04/meam520/","link":"","permalink":"https://happywalkers.github.io/2023/09/04/meam520/","excerpt":"","text":"Report","categories":[],"tags":[{"name":"Robotics","slug":"Robotics","permalink":"https://happywalkers.github.io/tags/Robotics/"}]},{"title":"Gems -- UE5 Game Development","slug":"UE5","date":"2023-01-01T19:53:58.000Z","updated":"2024-02-24T23:46:06.873Z","comments":true,"path":"2023/01/01/UE5/","link":"","permalink":"https://happywalkers.github.io/2023/01/01/UE5/","excerpt":"","text":"IntroductionBasically, it’s a first person collecting game. Presentation At first, I try to design a new map but find a better alternative, FANTASTIC - Village Pack .","categories":[],"tags":[{"name":"UE5","slug":"UE5","permalink":"https://happywalkers.github.io/tags/UE5/"}]},{"title":"Web application: A course review and comments website","slug":"webApp","date":"2023-01-01T19:53:58.000Z","updated":"2024-02-24T23:46:06.873Z","comments":true,"path":"2023/01/01/webApp/","link":"","permalink":"https://happywalkers.github.io/2023/01/01/webApp/","excerpt":"","text":"IntroductionIn the first version, I developed the web with Django and host it with Amazon EC2, a wonderful service provided by AWS.In the second version, I change to Spring Boot and Angular to provide a better front end GUI, and I would like to present some pictures of the second-version-web. PresentationHome pageEvery course here is a card or widget with two buttons at the right corner. It’s a very clear way to display its key information. Create a new courseUsing the button at the top menu bar, we can create a new course by filling its information in the form.Now, the created course is displayed at the bottom line. Update a courseWe can update the information by clicking the pencil icon at the right corner of a widget. In this case, we choose to update the cover image URL of the test course.Now, the widget of test course obtains a better looking cover image. Delete a courseIf we want to delete an expired course, we can push the cross button at a widget’s right corner.In this case, we try deleting the Introduction for Blockchain and Money.Now, it’s gone. Search for a courseWe can search for a course using its name, description, college, etc. Source codeFirst versionhttps://github.com/HappyWalkers/studentLifeWeb.git Second versionFront end: https://github.com/HappyWalkers/studentLife2FrontEnd.gitBack end: https://github.com/HappyWalkers/StudentLife2Backend.git","categories":[],"tags":[{"name":"Web","slug":"Web","permalink":"https://happywalkers.github.io/tags/Web/"}]},{"title":"Positional Embedding in Transformer","slug":"ESE546","date":"2022-12-31T19:53:58.000Z","updated":"2024-02-25T03:33:26.358Z","comments":true,"path":"2022/12/31/ESE546/","link":"","permalink":"https://happywalkers.github.io/2022/12/31/ESE546/","excerpt":"","text":"We prove that the summation of positional embedding and word embedding is a specific case of concatenation Report Source codehttps://github.com/HappyWalkers/ESE546Project.git","categories":[],"tags":[{"name":"Deep Learning","slug":"Deep-Learning","permalink":"https://happywalkers.github.io/tags/Deep-Learning/"}]},{"title":"Quantize the Network","slug":"ESE539","date":"2022-12-30T19:53:58.000Z","updated":"2024-02-25T03:33:48.071Z","comments":true,"path":"2022/12/30/ESE539/","link":"","permalink":"https://happywalkers.github.io/2022/12/30/ESE539/","excerpt":"","text":"Among all the methods that can alleviate computational workload during the training process, BinaryConnect is especially effective by binarizing the weights to +1 and -1 during the training process. However, there has been debate about which binarization method is the best over time. Therefore, we reproduced the work of the original BinaryConnect paper and examined the authors’ results. We also proposed two new binarization methods and discussed their performance. Report Source codehttps://github.com/HappyWalkers/ESE_539_Project.git","categories":[],"tags":[{"name":"Deep Learning","slug":"Deep-Learning","permalink":"https://happywalkers.github.io/tags/Deep-Learning/"}]},{"title":"Smart Home Systems","slug":"smart-home-system","date":"2022-12-29T19:53:58.000Z","updated":"2024-02-24T23:46:06.873Z","comments":true,"path":"2022/12/29/smart-home-system/","link":"","permalink":"https://happywalkers.github.io/2022/12/29/smart-home-system/","excerpt":"","text":"Introduction // the embedded code Our work is an overall system, constructing a one-stop smart home solution from different perspectives, mainly including three modules: smart door control, smart home appliance control, and active health monitoring. Smart Gate ControlSmart Gate Control is a face recognition system based on computer vision technology and deep learning. Its core is a Raspberry Pi 4B and an external camera. We trained a residual network for face recognition, and implemented a graphical user interface using PyQt, allowing users to complete face recognition with just a tap of a button, allowing the automatic control system to open the door. Smart Appliance ControlSmart home appliance control is a user-friendly interactive system developed based on embedded technology. Its core is a STM32 development board, which provides a rich interface as our development platform. We use a touch display screen to provide a graphical user interface, and send signals to control home appliances through the user’s clicks. The current demo realizes the switching of curtains and lights. We use STM32F429 to control the stepper motor to drive the curtain movement. The user can realize the opening and closing of the curtain by pressing the button or touching the button on the touch screen. At the same time, the GPIO of STM32F429 is used to control the relay corresponding to the light, so that the user can remotely control the indoor lighting when touching the capacitive LCD touch screen. Robot-following health monitoringThe robot-following health monitoring module senses the strength of the signal through the radar and other sensing devices equipped with the smart home robot, locates the human body, identifies obstacles, and dynamically plans the path. Realize the automatic follow-up of the care object. The automatic follow function of the smart home robot can locate the location of the caretaker in real time, and record the movement of the caretaker with a camera. Provide better security for vulnerable groups living alone. In the process of realizing automatic follow-up, the care module adopts the yolo framework of deep learning to realize the posture detection of the followed target and judge whether the care target has fallen. Studies have shown that the total case fatality rate of the elderly who falls is 5 times higher than that of the elderly without falls, and the case fatality rate of those who cannot stand up 1 hour after the fall is even twice as high. In the process of caring for vulnerable groups living alone, timely monitoring of falls is of great significance. Through the automatic follow-up and fall detection functions in the nursing module of the smart home robot, the risk of death or injury caused by the accidental fall of the elderly can be greatly reduced. In short, the automation and intelligence of home life is the current development trend of information appliances. I believe that this system will definitely arouse people’s interest and have a wider range of application scenarios after being improved.","categories":[],"tags":[{"name":"Embedded Systems","slug":"Embedded-Systems","permalink":"https://happywalkers.github.io/tags/Embedded-Systems/"}]},{"title":"Hexo","slug":"hexo","date":"2022-12-28T21:28:17.000Z","updated":"2024-02-24T23:46:06.873Z","comments":true,"path":"2022/12/28/hexo/","link":"","permalink":"https://happywalkers.github.io/2022/12/28/hexo/","excerpt":"","text":"HexoHexo is another tool that helps post blog. CommandsCreate a new blog: 1hexo new another-post Deploy the new blog: 123hexo generatehexo cleanhexo deploy Remember to add this line after a short description of this post: 1&lt;!-- more --&gt; When using the embedded code of an online video, such as the videos on Youtube or Bilibili, we could use the flowing line to adjust the size of the video window: 123&lt;div class=&quot;mdui-video-container&quot;&gt; &lt;iframe src=&quot;//player.bilibili.com/player.html?aid=684730157&amp;bvid=BV1BU4y197dp&amp;cid=738874866&amp;page=1&quot; scrolling=&quot;no&quot; border=&quot;0&quot; frameborder=&quot;no&quot; framespacing=&quot;0&quot; allowfullscreen=&quot;true&quot;&gt; &lt;/iframe&gt; // the embedded code&lt;/div&gt; To set the cover of a post, you need to set the ‘cover’ value in the front-matter: 1234567---title: Hello Worlddate: 2013/7/13 20:46:25cover: https://s2.loli.net/2024/02/24/6le2zdjBODXmsr7.pngcoverWidth: 1200coverHeight: 750--- Using the plugin, we could display pdf directly on our blogs. For files on google drive, we could use: 1&#123;% pdf https://drive.google.com/file/d/0B6qSwdwPxPRdTEliX0dhQ2JfUEU/preview %&#125; Create the blog with HexoSome tutorialsOfficial Documents Github repository of Hexo How to use Hexo and deploy to GitHub Pages NoteThe configuration file “_config.yml” in the root directory of the Hexo project is important. Check this page to edit it. This page tell you how to host a Hexo blog with github. There are a lot of pretty and free themes on the official web. And follow the steps to apply your favorite theme. I use this theme because it allows me to present many pictures in the home page.","categories":[],"tags":[{"name":"Blog","slug":"Blog","permalink":"https://happywalkers.github.io/tags/Blog/"}]}],"categories":[],"tags":[{"name":"Distributed System","slug":"Distributed-System","permalink":"https://happywalkers.github.io/tags/Distributed-System/"},{"name":"Distributed Systems","slug":"Distributed-Systems","permalink":"https://happywalkers.github.io/tags/Distributed-Systems/"},{"name":"Robotics","slug":"Robotics","permalink":"https://happywalkers.github.io/tags/Robotics/"},{"name":"UE5","slug":"UE5","permalink":"https://happywalkers.github.io/tags/UE5/"},{"name":"Web","slug":"Web","permalink":"https://happywalkers.github.io/tags/Web/"},{"name":"Deep Learning","slug":"Deep-Learning","permalink":"https://happywalkers.github.io/tags/Deep-Learning/"},{"name":"Embedded Systems","slug":"Embedded-Systems","permalink":"https://happywalkers.github.io/tags/Embedded-Systems/"},{"name":"Blog","slug":"Blog","permalink":"https://happywalkers.github.io/tags/Blog/"}]}